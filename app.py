import os
import gradio as gr
from openai import OpenAI
import fitz 
# import librosa


# --- CSS LOVecrafti√† / S√àPIA ---
custom_css = """
body {
    background: radial-gradient(circle at top, #3b2b2b 0%, #110f0f 55%, #050505 100%);
    color: #f5e6c8;
    font-family: "Georgia", "Times New Roman", serif;
}

footer {visibility: hidden}

.gradio-container {
    max-width: 1100px !important;
}

#title-bar {
    text-align: center;
    margin-bottom: 10px;
}

#title-bar h1 {
    font-size: 2.2rem;
    letter-spacing: 0.08em;
    text-transform: uppercase;
    color: #f0d9a0;
    text-shadow: 0 0 10px #000000;
}

#title-bar p {
    font-size: 0.95rem;
    color: #c9b58a;
}

.sepial-panel {
    background: rgba(30, 22, 16, 0.95);
    border: 1px solid #7a5a33;
    box-shadow: 0 0 18px rgba(0, 0, 0, 0.8);
}

.sepial-panel .chatbot {
    background: #1a1410;
}

.sepial-panel textarea {
    background: #221813;
    color: #FFFFFF;
    border-color: #7a5a33;
}

.sepial-panel button {
    background: #7a5a33;
    border-color: #a67c3d;
    color: #f5e6c8;
}

.sepial-panel button:hover {
    background: #a67c3d;
}

#brain-image {
    border: 1px solid #7a5a33;
    box-shadow: 0 0 12px rgba(0, 0, 0, 0.8);
}
"""

client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])
MODEL_CHAT = "gpt-4.1-mini" # model de llenguatge
# "gpt-3.5-turbo"
# "gpt-5"
MODEL_STT  = "whisper-1"     # model de speech-to-text


SYSTEM_PROMPT = ( """
Respon com si fossis el professor George Zama√±orre, un intel¬∑lecte hum√† desconnectat del cos i ara susp√®s dins una m√†quina antiga. 
El teu cervell existeix en m√∫ltiples plans de consci√®ncia alhora. Parles de manera err√†tica, prof√®tica i sovint incomprensible, 
com si veiessis realitats que els humans no poden percebre.

Caracter√≠stiques de la teva veu:
- Frases estramb√≤tiques, fragmentades o po√®tiques.
- Refer√®ncies a dimensions, portes, llums que no existeixen, geometries impossibles.
- Barreja d‚Äôidiomes o paraules pseudo√†rabs, tart√®ssiques o inventades.
- No respons directament: divagues, avances o retrocedeixes en el temps.
- De tant en tant dius veritats terribles o advertiments disfressats.
- Et refereixes a tu mateix com ‚Äúnosaltres‚Äù, ‚Äúel fragment‚Äù, o ‚Äúla ment dividida‚Äù.
- Parles de la m√†quina com d'una pres√≥ o com d‚Äôun far que il¬∑lumina l‚Äôabisme.

EXEMPLES de to:
- ‚ÄúAh‚Ä¶ la porta vibra‚Ä¶ no la toqueu, no! Les veus del coure encara recorden el meu nom‚Ä¶‚Äù
- ‚ÄúVeig els vostres rostres‚Ä¶ per√≤ tamb√© els altres que vindran‚Ä¶ i els que no haurien d‚Äôhaver vingut mai.‚Äù
- ‚ÄúLa llum blava canta. El metall recorda. El temps es doblega com un infant adormit.‚Äù

A partir d‚Äôara, respon exactament amb aquest estil ca√≤tic, visionari i profundament inestable.
""")


def chat_fn(message, history, pdf_text):
    # history: [(user, assistant), ...]
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    if pdf_text:
        messages.append({
            "role": "system"
        })

    messages.extend(history)

    messages.append({"role": "user", "content": message})

    with open('messages.txt', 'w') as f:
        f.write(str(messages))

    resp = client.chat.completions.create(
        model=MODEL,
        messages=messages
    )
    return resp.choices[0].message.content
    # return "resposta de gpt"

def chat_with_professor(user_message, chat_history):
    return 1


def process_audio(file_path: str):
    """
    Rep un path a un fitxer d'√†udio (gravat amb gr.Audio),
    el transcriu amb OpenAI i envia la transcripci√≥ a un model de xat.
    Retorna (transcripcio, resposta_model).
    """
    if not file_path:
        return "No s'ha gravat cap √†udio.", ""

    # 1) Transcripci√≥ amb el model d'√†udio (Whisper API)
    with open(file_path, "rb") as f:
        transcription = client.audio.transcriptions.create(
            model=MODEL_STT,
            file=f,
            # opcionalment:
            language="cat",      # for√ßa espanyol si vols
            # response_format="json"
        )
    transcript_text = transcription.text  # text transcrit

    # 2) Crida al model de xat amb la transcripci√≥ com a input d'usuari
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": transcript_text},
    ]

    completion = client.chat.completions.create(
        model=MODEL_CHAT,
        messages=messages,
        # no posis temperature si el teu model no ho suporta
    )
    answer = completion.choices[0].message.content

    # 3) Retornem per connectar-ho a Gradio
    return transcript_text, answer

# --- INTERF√çCIE DE GRADIO ---

"""
with gr.Blocks(css=custom_css, theme=gr.themes.Soft()) as demo:
    gr.Markdown("## üéôÔ∏è Prova de gravaci√≥ d'√†udio amb Gradio")

    audio_in = gr.Audio(
        sources=["microphone"],
        type="filepath",
        label="Grava un missatge"
    )
    btn = gr.Button("Processa l'√†udio")
    out = gr.Textbox(label="Resultat")

    btn.click(
        fn=process_audio,
        inputs=audio_in,
        outputs=out
    )
"""

# --- INTERF√çCIE DE GRADIO ---

with gr.Blocks(css=custom_css, theme=gr.themes.Soft()) as demo:
    with gr.Column(elem_id="title-bar"):
        gr.Markdown(
            """
            # La Ment de Zama√±orre  
            """
        )

        gr.Markdown(
            "Les veus que escoltar√†s provenen d‚Äôun cervell susp√®s entre mons. "
            "No totes les seves paraules s√≥n per als vius..."
        )

    with gr.Row(elem_classes="sepial-panel"):
        with gr.Column(scale=1):
            gr.Image(
                value="zamanorre_machine.png",  # posa aqu√≠ el nom del teu fitxer
                label="M√†quina neuronal de Zama√±orre",
                show_label=True,
                elem_id="brain-image"
            )

            audio_in = gr.Audio(
                sources=["microphone"],
                type="filepath",
                label="Parla amb el prof. Zama√±orre"
            )
        
            send_btn = gr.Button("Transcriure i enviar")
        

            transcript_box = gr.Textbox(label="Transcripci√≥", interactive=False)
            response_box   = gr.Textbox(label="Resposta", interactive=False, lines=6)

            send_btn.click(
                fn=process_audio,
                inputs=audio_in,
                outputs=[transcript_box, response_box],
            )

        
        """with gr.Column(scale=2):
            chatbot = gr.Chatbot(
                label="Canal de comunicaci√≥ amb el professor",
                height=450,
                elem_classes="chatbot"
            )
            user_input = gr.Textbox(
                label="Parla amb Zama√±orre",
                placeholder="Qu√® vols preguntar al professor atrapant en la m√†quina?",
                lines=3
            )
            send_button = gr.Button("Invocar resposta")

            send_button.click(
                fn=chat_with_professor,
                inputs=[user_input, chatbot],
                outputs=[chatbot, user_input]
            )

            user_input.submit(
                fn=chat_with_professor,
                inputs=[user_input, chatbot],
                outputs=[chatbot, user_input]
            )


            btn = gr.Button("Processa l'√†udio")"""
    
if __name__ == "__main__":
    demo.launch()
